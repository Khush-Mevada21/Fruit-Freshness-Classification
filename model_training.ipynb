{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c24ee9-a3ef-4586-8b1e-6d89427d809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca0bd63-22a8-4783-b307-018bca0d9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"FreshHarvest_Dataset/FRUIT-16K\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869a6f1b-454d-4b50-8b83-b3dc9509ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD DATASETS WITH TRANSFORMS\n",
    "\n",
    "full_dataset = datasets.ImageFolder(dataset_path)\n",
    "\n",
    "# Train: 70%, Val: 15%, Test: 15%\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "test_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95da972-c55c-4e05-a8ca-da6e588767d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5681b78-4a94-4ec9-955a-6d12328598eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Train: 90.00% | Val: 98.21%\n",
      "ðŸ”¥ Saved new best model!\n",
      "Epoch 2/3 | Train: 98.54% | Val: 99.17%\n",
      "ðŸ”¥ Saved new best model!\n",
      "Epoch 3/3 | Train: 99.18% | Val: 99.17%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train: {train_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), \"best_resnet50.pth\")\n",
    "        print(\"ðŸ”¥ Saved new best model!\")\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab897294-512d-4273-9f71-689fdad1887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Final Test Accuracy: 99.25%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"ðŸ”¥ Final Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed04499-8404-4850-8650-60d83d79b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model + class mapping + preprocess saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"resnet50_fruit_model.pth\")\n",
    "\n",
    "with open(\"class_to_idx.json\", \"w\") as f:\n",
    "    json.dump(full_dataset.class_to_idx, f)\n",
    "\n",
    "with open(\"preprocess.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_test_transform, f)\n",
    "\n",
    "print(\"Model + class mapping + preprocess saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a4687-e40a-4585-a639-45b7e1990491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
